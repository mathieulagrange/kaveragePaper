\documentclass[a4paper,fleqn]{article} 
\usepackage{graphicx} 
\usepackage{morefloats,textcomp} 
\usepackage{amsmath} 
\usepackage{amssymb} 
\usepackage{rotating,url} 


\title{Efficient similarity-based data clustering by optimal object to cluster reallocation}

% TODO explain dummy mode

\begin{document} 
\maketitle
%\pagestyle{empty}


%\pagestyle{plain}
Dear Sir/Madam,

in our humble opinion, the paper have been rejected without proper evaluation with a claim of lack of novelty that is not properly motivated by published research papers addressing the issue studied in the submitted paper.

In this respect, we ask the editorial office to reconsider this decision and allow the submitted paper to enter in the review process.

Please find below a copy of the decision of the associate editor and our answer which at this time did not received any answer from the associate editor.

Best regards,

Mathieu Lagrange



\section{Decision from Mr Vichi 20/01/2016}

I would think that the idea to partition by maximizing suitable
aggregates of average intra-cluster similarity has been around for quite
some time now, and implemented e.g. in the CLUTO software of G Karypis \\
(see http://glaros.dtc.umn.edu/gkhome/cluto/cluto/download: the tar.gz
to download provides the manual, and page 10 of that has a table of the
variants implemented).

So the approach is not new, and I don't think the proposed algorithm is
either.  (My experience is that solution heuristics based on single
element moves often get stuck in local minima, which can be improved by
using Kernighan-Lin type move chains for length > 1 (usually, going up
to 3 works much better).)

To warrant publication we would really need to see more innovation, or
much more extensive performance analysis and bechmarking.


\section{Answer from the authors 02/02/2106}

Dear Sir,

I am writing you concerning your reply to of our submission to the ADAC journal. The rapid review which you transmitted to us raises several concerns about our submission that we believe are not quite admissible.

The fact that the optimization of the average intra class similarity is not new is perfectly true, and we point that fact out ourselves in the paper. This being said, to the best of our knowledge, no paper thoroughly presenting an efficient algorithm that optimizes this criterion and the proof of its convergence has been published to this day; and the current de facto standard in similarity-based clustering consists in using the kernel k-means algorithm, potentially with some sort of normalization in order to turn the similarity matrix into a Gram matrix.

Pending convincing demonstration of the opposite, we therefore maintain that our paper presents : 

  1.  an efficient algorithm for the optimization of the average intra class similarity,

 2.   a proof of its convergence,

 3.   a detailed complexity analysis, both theoretical and applied, showing significant performance improvement relative to the established standard,

 4.   a thorough and extensive experimental validation on 48 datasets.


In our opinion, stating that the presence of an formally undescribed algorithm in some toolbox precludes later publications on the topic addressed by the toolbox is too light an argument to exclude a paper from proper evaluation.

For those reasons, I ask you to either reconsider your decision, or provide us with an actual bibliographic reference presenting -- or dismissing -- the algorithm we propose.

Best regards,

Mathieu Lagrange



\end{document}